{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating names with recurrent neural networks (5 points)\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token+name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(names))\n",
    "for x in names[::1000]:\n",
    "    print (x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZhlzCJiZZcwhYGaWMYeAmVnG/j9X9jq2BqwyjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204073dc208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len,names))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len,names)),bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need next to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  55\n"
     ]
    }
   ],
   "source": [
    "#all unique characters go here\n",
    "tokens = set(\"\".join(names))\n",
    "\n",
    "\n",
    "tokens = list(tokens)\n",
    "\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!token_to_id = <dictionary of symbol -> its identifier (index in tokens list)>\n",
    "token_to_id = {t:i for i,t in enumerate(tokens) }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(names,max_len=None,pad=token_to_id[' '],dtype='int32'):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len,names))\n",
    "    names_ix = np.zeros([len(names),max_len],dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get,names[i]))\n",
    "        names_ix[i,:len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[ 5 27 10  0 17  0  9 37  5]\n",
      " [ 5 41 37 16 38 35  5  5  5]\n",
      " [ 5 33 38 25 20 20 25  9  5]\n",
      " [ 5 41 25 16 15  0 21 21  9]]\n"
     ]
    }
   ],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=480>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Concatenate,Dense,Embedding\n",
    "\n",
    "rnn_num_units = 64\n",
    "embedding_size = 16\n",
    "\n",
    "#Let's create layers for our recurrent network\n",
    "#Note: we create layers but we don't \"apply\" them yet\n",
    "embed_x = Embedding(n_tokens,embedding_size) # an embedding layer that converts character ids into embeddings\n",
    "get_h_next = <a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1>.  \n",
    "get_probas = <a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1). \n",
    "\n",
    "#Note: please either set the correct activation to Dense or write it manually in rnn_one_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces next state and output\n",
    "    given prev input and previous state.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    Follow inline isntructions to complete the function.\n",
    "    \"\"\"\n",
    "    #convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t,[-1,1]))[:,0]\n",
    "    \n",
    "    x_and_h = <concatenate x embedding and previous h state>\n",
    "    \n",
    "    h_next = <compute next state given x_and_h>\n",
    "    \n",
    "    output_probas = <get probabilities for language model P(x_next|h_next)>\n",
    "    \n",
    "    return output_probas,h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN loop\n",
    "\n",
    "Once rnn_one_step is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder('int32',(MAX_LENGTH,None))\n",
    "batch_size = tf.shape(input_sequence)[1]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size,rnn_num_units]) #initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[t]\n",
    "    probas_next,h_next = rnn_one_step(x_t,h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "predicted_probas = tf.stack(predicted_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_matrix = tf.reshape(predicted_probas[:-1],[-1,len(tokens)])\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[1:],[-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = <define loss as categorical crossentropy. Mind that predictions are probabilities and NOT logits!>\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "s = keras.backend.get_session()\n",
    "s.run(tf.global_variables_initializer())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names,32),max_len=MAX_LENGTH)\n",
    "    loss_i,_ = s.run([loss,optimize],{input_sequence:batch})\n",
    "    \n",
    "    \n",
    "    history.append(loss_i)\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder('int32',(None,))\n",
    "h_t = tf.Variable(np.zeros([1,rnn_num_units],'float32'))\n",
    "\n",
    "next_probs,next_h = rnn_one_step(x_t,h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=' ',max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "        \n",
    "    parameters:\n",
    "        The phrase is set using the variable seed_phrase\n",
    "        The optional input \"N\" is used to set the number of characters of text to predict.     \n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t,h_t.initial_value))\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t,next_h),{x_t:[ix]})\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs,tf.assign(h_t,next_h)],{x_t:[x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens,p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: try it out!\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* Ikea catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coming next\n",
    "\n",
    "* The easy way to train recurrent neural networks in Keras\n",
    "* Other problems solved with RNNs: sequence classification, sequential labelling\n",
    "* LSTM, GRU, OMGWTF\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "```\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from keras, there's also a friendly tensorflow API for recurrent neural nets. It's based around the symbolic loop function (aka [scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self,input,state):\n",
    "        return rnn_one_step(input[:,0],state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "\n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder('int32',(None,None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell,input_sequence[:,:,None],\n",
    "                                                 time_major=True,dtype='float32')\n",
    "\n",
    "print predicted_probas.eval({input_sequence:to_matrix(names[:10],max_len=50)}).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use the all the pre-implemented RNN cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for obj in dir(tf.nn.rnn_cell)+dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print (obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder('int32',(None,None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence,last_state = tf.nn.dynamic_rnn(cell,inputs_embedded,dtype='float32')\n",
    "\n",
    "print('LSTM visible states[time,batch,unit]:', state_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
