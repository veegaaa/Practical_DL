
[__Lecture slides__](https://yadi.sk/i/LdEIut2z3MjPMv)
## Materials
- [main stuff from cs231](http://cs231n.github.io/linear-classify/)
* Lecture on deep learning (russian) - [url](https://www.youtube.com/watch?v=8008XQzoUEs)
* Intro to neural nets and backprop (english) - [url](https://www.youtube.com/watch?v=uXt8qF2Zzfo)


* Stochastic Gradient Descent
  - [A blog post overview of gradient descent methods](http://ruder.io/optimizing-gradient-descent/)
  - [wikipedia on SGD :)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent), expecially the "extensions and variants" section
  - [Cool interactive demo of momentum](http://distill.pub/2017/momentum/)
  - [RMSPROP video](https://www.youtube.com/watch?v=defQQqkXEfE)

* Neural nets and backprop
  - [Backprop by cs231](http://cs231n.github.io/optimization-2/)
  - [Notation](http://cs231n.github.io/neural-networks-1/#nn)
  - Interactive [neural network playground](http://playground.tensorflow.org/) in your browser
  - pretty much all the module 1 of http://cs231n.github.io/


## Assignment

Your first assignment consists of two parts:
* Part I, where you implement simple logistic regression and train it with adaptive SGD modiffications
* Part II, where you implement a simple neural network in pure numpy

Both those notebooks are in current folder under respective names.
